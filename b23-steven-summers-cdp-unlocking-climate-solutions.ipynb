{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":404,"outputs":[{"output_type":"stream","text":"/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Climate Change/Full_Corporations_Response_Data_Dictionary copy.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Climate Change/2020_Full_Climate_Change_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Climate Change/2019_Full_Climate_Change_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Climate Change/2018_Full_Climate_Change_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Water Security/Full_Corporations_Response_Data_Dictionary.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Water Security/2019_Full_Water_Security_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Water Security/2020_Full_Water_Security_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Responses/Water Security/2018_Full_Water_Security_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Climate Change/2020_Climate_Change_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Climate Change/2018_Climate_Change_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Climate Change/2019_Climate_Change_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Climate Change/CDP-climate-change-changes-document.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Water Security/2020_Water_Security_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Water Security/CDP-water-changes-document.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Water Security/2019_Water_Security_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Questionnaires/Water Security/2018_Water_Security_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Climate Change/2019_Corporates_Disclosing_to_CDP_Climate_Change.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Climate Change/2020_Corporates_Disclosing_to_CDP_Climate_Change.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Climate Change/Corporations_Disclosing_to_CDP_Data_Dictionary.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Climate Change/2018_Corporates_Disclosing_to_CDP_Climate_Change.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Water Security/2018_Corporates_Disclosing_to_CDP_Water_Security.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Water Security/Corporations_Disclosing_to_CDP_Data_Dictionary.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Water Security/2019_Corporates_Disclosing_to_CDP_Water_Security.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Water Security/2020_Corporates_Disclosing_to_CDP_Water_Security.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/NYC CDP Census Tract Shapefiles/nyu_2451_34505_iso.xml\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/NYC CDP Census Tract Shapefiles/nyu_2451_34505.dbf\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/NYC CDP Census Tract Shapefiles/nyu_2451_34505.shp\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/NYC CDP Census Tract Shapefiles/nyu_2451_34505.prj\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/NYC CDP Census Tract Shapefiles/nyu_2451_34505.shx\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/CDC Social Vulnerability Index 2018/SVI2018_US.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/CDC Social Vulnerability Index 2018/SVI2018_US_COUNTY.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/Recommendations from CDP/CDP_recommendations_for_supplementary_datasets_to_include.xlsx\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/Recommendations from CDP/CDP_recommendations_for_questions_to_focus_on.xlsx\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/Simple Maps US Cities Data/uscities.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/Locations of Corporations/NA_HQ_public_data.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/CDC 500 Cities Census Tract Data/500_Cities__Census_Tract-level_Data__GIS_Friendly_Format___2019_release.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/Dataset Licenses/Supplementary_dataset_licenses.txt\n/kaggle/input/cdp-unlocking-climate-solutions/Supplementary Data/Dataset Licenses/CDP_dataset_licenses.txt\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Questionnaires/2020_Cities_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Questionnaires/2018_Cities_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Questionnaires/2019_Cities_Questionnaire.pdf\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Disclosing/2019_Cities_Disclosing_to_CDP.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Disclosing/2018_Cities_Disclosing_to_CDP.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Disclosing/Cities_Disclosing_to_CDP_Data_Dictionary.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Disclosing/2020_Cities_Disclosing_to_CDP.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Responses/2018_Full_Cities_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Responses/2020_Full_Cities_Dataset.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Responses/Full_Cities_Response_Data_Dictionary.csv\n/kaggle/input/cdp-unlocking-climate-solutions/Cities/Cities Responses/2019_Full_Cities_Dataset.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cities_2020_df = pd.read_csv(\"../input/cdp-unlocking-climate-solutions/Cities/Cities Responses/2020_Full_Cities_Dataset.csv\")\ncities_2019_df = pd.read_csv(\"../input/cdp-unlocking-climate-solutions/Cities/Cities Responses/2019_Full_Cities_Dataset.csv\")","execution_count":405,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_question = cities_2019_df[cities_2019_df['Question Number'] == '2.2']\\\n    .rename(columns={'Organization': 'City'})\n\ntest_question.head()","execution_count":406,"outputs":[{"output_type":"execute_result","execution_count":406,"data":{"text/plain":"   Questionnaire  Year Reported to CDP  Account Number  \\\n12   Cities 2019                  2019           60073   \n47   Cities 2019                  2019           35873   \n60   Cities 2019                  2019           49333   \n63   Cities 2019                  2019           35867   \n69   Cities 2019                  2019           49333   \n\n                                   City  \\\n12           Wolverhampton City Council   \n47             Municipality of Medell√≠n   \n60               City of Louisville, KY   \n63  Region Metropolitana de Guadalajara   \n69               City of Louisville, KY   \n\n                                              Country     CDP Region  \\\n12  United Kingdom of Great Britain and Northern I...         Europe   \n47                                           Colombia  Latin America   \n60                           United States of America  North America   \n63                                             Mexico  Latin America   \n69                           United States of America  North America   \n\n                     Parent Section          Section Question Number  \\\n12  Climate Hazards & Vulnerability  Climate Hazards             2.2   \n47  Climate Hazards & Vulnerability  Climate Hazards             2.2   \n60  Climate Hazards & Vulnerability  Climate Hazards             2.2   \n63  Climate Hazards & Vulnerability  Climate Hazards             2.2   \n69  Climate Hazards & Vulnerability  Climate Hazards             2.2   \n\n                                        Question Name  Column Number  \\\n12  Please identify and describe the factors that ...              2   \n47  Please identify and describe the factors that ...              1   \n60  Please identify and describe the factors that ...              3   \n63  Please identify and describe the factors that ...              1   \n69  Please identify and describe the factors that ...              2   \n\n                                          Column Name  Row Number Row Name  \\\n12                                Support / Challenge           8      NaN   \n47               Factors that affect ability to adapt           9      NaN   \n60  Please describe the factor and the degree to w...           4      NaN   \n63               Factors that affect ability to adapt           1      NaN   \n69                                Support / Challenge           1      NaN   \n\n                                      Response Answer Comments File Name  \\\n12                                          Challenge      NaN       NaN   \n47                                  Land use planning      NaN       NaN   \n60  The Housing Needs Assessment, released in draf...      NaN       NaN   \n63                           Access to basic services      NaN       NaN   \n69                                            Support      NaN       NaN   \n\n               Last update  \n12  24/06/2020 05:30:36 AM  \n47  24/06/2020 05:30:36 AM  \n60  24/06/2020 05:30:36 AM  \n63  24/06/2020 05:30:36 AM  \n69  24/06/2020 05:30:36 AM  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questionnaire</th>\n      <th>Year Reported to CDP</th>\n      <th>Account Number</th>\n      <th>City</th>\n      <th>Country</th>\n      <th>CDP Region</th>\n      <th>Parent Section</th>\n      <th>Section</th>\n      <th>Question Number</th>\n      <th>Question Name</th>\n      <th>Column Number</th>\n      <th>Column Name</th>\n      <th>Row Number</th>\n      <th>Row Name</th>\n      <th>Response Answer</th>\n      <th>Comments</th>\n      <th>File Name</th>\n      <th>Last update</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>Cities 2019</td>\n      <td>2019</td>\n      <td>60073</td>\n      <td>Wolverhampton City Council</td>\n      <td>United Kingdom of Great Britain and Northern I...</td>\n      <td>Europe</td>\n      <td>Climate Hazards &amp; Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>2</td>\n      <td>Support / Challenge</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>Challenge</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24/06/2020 05:30:36 AM</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Cities 2019</td>\n      <td>2019</td>\n      <td>35873</td>\n      <td>Municipality of Medell√≠n</td>\n      <td>Colombia</td>\n      <td>Latin America</td>\n      <td>Climate Hazards &amp; Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>1</td>\n      <td>Factors that affect ability to adapt</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>Land use planning</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24/06/2020 05:30:36 AM</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Cities 2019</td>\n      <td>2019</td>\n      <td>49333</td>\n      <td>City of Louisville, KY</td>\n      <td>United States of America</td>\n      <td>North America</td>\n      <td>Climate Hazards &amp; Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>3</td>\n      <td>Please describe the factor and the degree to w...</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>The Housing Needs Assessment, released in draf...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24/06/2020 05:30:36 AM</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>Cities 2019</td>\n      <td>2019</td>\n      <td>35867</td>\n      <td>Region Metropolitana de Guadalajara</td>\n      <td>Mexico</td>\n      <td>Latin America</td>\n      <td>Climate Hazards &amp; Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>1</td>\n      <td>Factors that affect ability to adapt</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Access to basic services</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24/06/2020 05:30:36 AM</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Cities 2019</td>\n      <td>2019</td>\n      <td>49333</td>\n      <td>City of Louisville, KY</td>\n      <td>United States of America</td>\n      <td>North America</td>\n      <td>Climate Hazards &amp; Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>2</td>\n      <td>Support / Challenge</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Support</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24/06/2020 05:30:36 AM</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentences = test_question[test_question['Column Number'] == 3]\\\n    .rename(columns={'Organization': 'City'})\n\ntest_sentences = test_sentences['Response Answer'].fillna('No Response')\n\ntest_data = np.array(test_sentences)\ntest_data = test_data.tolist()","execution_count":407,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_2_2 = cities_2020_df[cities_2020_df['Question Number'] == '2.2']\\\n    .rename(columns={'Organization': 'City'})\n\ncities_2_2.head()","execution_count":408,"outputs":[{"output_type":"execute_result","execution_count":408,"data":{"text/plain":"    Questionnaire  Year Reported to CDP  Account Number  \\\n59    Cities 2020                  2020          834058   \n96    Cities 2020                  2020           36274   \n156   Cities 2020                  2020           31109   \n222   Cities 2020                  2020           74418   \n320   Cities 2020                  2020          834374   \n\n                         City                   Country  \\\n59              Bogor Regency                 Indonesia   \n96          Comune di Bologna                     Italy   \n156         City of Melbourne                 Australia   \n222  Town of Breckenridge, CO  United States of America   \n320                Tagum City               Philippines   \n\n                     CDP Region                     Parent Section  \\\n59   Southeast Asia and Oceania  Climate Hazards and Vulnerability   \n96                       Europe  Climate Hazards and Vulnerability   \n156  Southeast Asia and Oceania  Climate Hazards and Vulnerability   \n222               North America  Climate Hazards and Vulnerability   \n320  Southeast Asia and Oceania  Climate Hazards and Vulnerability   \n\n             Section Question Number  \\\n59   Climate Hazards             2.2   \n96   Climate Hazards             2.2   \n156  Climate Hazards             2.2   \n222  Climate Hazards             2.2   \n320  Climate Hazards             2.2   \n\n                                         Question Name  Column Number  \\\n59   Please identify and describe the factors that ...              2   \n96   Please identify and describe the factors that ...              3   \n156  Please identify and describe the factors that ...              3   \n222  Please identify and describe the factors that ...              4   \n320  Please identify and describe the factors that ...              1   \n\n                                           Column Name  Row Number Row Name  \\\n59   Indicate if this factor either supports or cha...           4      NaN   \n96   Level of degree to which factor challenges/sup...           5      NaN   \n156  Level of degree to which factor challenges/sup...           1      NaN   \n222  Please describe how the factor supports or cha...           1      NaN   \n320               Factors that affect ability to adapt           1      NaN   \n\n                                       Response Answer Comments File Name  \\\n59                                            Supports      NaN       NaN   \n96                                                 NaN      NaN       NaN   \n156                           Significantly challenges      NaN       NaN   \n222  Cost of living is high and many properties are...      NaN       NaN   \n320                               Access to healthcare      NaN       NaN   \n\n                Last update  \n59   09/07/2020 09:45:36 AM  \n96   09/07/2020 09:45:36 AM  \n156  09/07/2020 09:45:36 AM  \n222  09/07/2020 09:45:36 AM  \n320  09/07/2020 09:45:36 AM  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questionnaire</th>\n      <th>Year Reported to CDP</th>\n      <th>Account Number</th>\n      <th>City</th>\n      <th>Country</th>\n      <th>CDP Region</th>\n      <th>Parent Section</th>\n      <th>Section</th>\n      <th>Question Number</th>\n      <th>Question Name</th>\n      <th>Column Number</th>\n      <th>Column Name</th>\n      <th>Row Number</th>\n      <th>Row Name</th>\n      <th>Response Answer</th>\n      <th>Comments</th>\n      <th>File Name</th>\n      <th>Last update</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59</th>\n      <td>Cities 2020</td>\n      <td>2020</td>\n      <td>834058</td>\n      <td>Bogor Regency</td>\n      <td>Indonesia</td>\n      <td>Southeast Asia and Oceania</td>\n      <td>Climate Hazards and Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>2</td>\n      <td>Indicate if this factor either supports or cha...</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>Supports</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>09/07/2020 09:45:36 AM</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Cities 2020</td>\n      <td>2020</td>\n      <td>36274</td>\n      <td>Comune di Bologna</td>\n      <td>Italy</td>\n      <td>Europe</td>\n      <td>Climate Hazards and Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>3</td>\n      <td>Level of degree to which factor challenges/sup...</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>09/07/2020 09:45:36 AM</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>Cities 2020</td>\n      <td>2020</td>\n      <td>31109</td>\n      <td>City of Melbourne</td>\n      <td>Australia</td>\n      <td>Southeast Asia and Oceania</td>\n      <td>Climate Hazards and Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>3</td>\n      <td>Level of degree to which factor challenges/sup...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Significantly challenges</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>09/07/2020 09:45:36 AM</td>\n    </tr>\n    <tr>\n      <th>222</th>\n      <td>Cities 2020</td>\n      <td>2020</td>\n      <td>74418</td>\n      <td>Town of Breckenridge, CO</td>\n      <td>United States of America</td>\n      <td>North America</td>\n      <td>Climate Hazards and Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>4</td>\n      <td>Please describe how the factor supports or cha...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Cost of living is high and many properties are...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>09/07/2020 09:45:36 AM</td>\n    </tr>\n    <tr>\n      <th>320</th>\n      <td>Cities 2020</td>\n      <td>2020</td>\n      <td>834374</td>\n      <td>Tagum City</td>\n      <td>Philippines</td>\n      <td>Southeast Asia and Oceania</td>\n      <td>Climate Hazards and Vulnerability</td>\n      <td>Climate Hazards</td>\n      <td>2.2</td>\n      <td>Please identify and describe the factors that ...</td>\n      <td>1</td>\n      <td>Factors that affect ability to adapt</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Access to healthcare</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>09/07/2020 09:45:36 AM</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = cities_2_2[cities_2_2['Column Number'] == 4]\\\n    .rename(columns={'Organization': 'City'})\n\ntext = text['Response Answer'].fillna('No Response')\n\ntext_list = text.tolist()","execution_count":409,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment = cities_2_2[cities_2_2['Column Number'] == 2]\\\n    .rename(columns={'Organization': 'City'})\n\nsentiment = sentiment['Response Answer'].fillna('No Response')\n\nsentiment_list = sentiment.tolist()\nsentiment_list = [2 if sentiment.strip() == 'Supports' else 1 if sentiment.strip() == 'Challenges' \n                    else 0 for sentiment in sentiment_list]","execution_count":410,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')","execution_count":411,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contractions = {\n\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"that's\" : \"that is\",\n\"there's\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\"\n}","execution_count":412,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from string import punctuation\n\ndef sentence_formatting(sentences):\n    all_sentences=list()\n    for text in sentences:\n        lower_case = text.lower()\n        words = lower_case.split()\n        reformed = [contractions[word] if word in contractions else word for word in words]\n        reformed_test=list()\n        for word in reformed:\n            if word not in stop_words:\n                reformed_test.append(word)\n        reformed = \" \".join(reformed_test) \n        punct_text = \"\".join([ch for ch in reformed if ch not in punctuation])\n        all_sentences.append(punct_text)\n    all_text = \" \".join(all_sentences)\n    all_words = all_text.split()\n    return all_sentences, all_words","execution_count":413,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter \n\nall_sentences, all_words = sentence_formatting(text_list)\ncount_words = Counter(all_words)\ntotal_words = len(all_words)\nsorted_words = count_words.most_common(total_words)\nvocab_to_int = {w:i+1 for i,(w,c) in enumerate(sorted_words)}","execution_count":414,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_sentences(sentences):\n    \n    all_sentences=list()\n    for text in sentences:\n        text = text.lower()\n        text = \"\".join([ch for ch in text if ch not in punctuation])\n        all_sentences.append(text)\n    encoded_sentences=list()\n    for sentence in all_sentences:\n        encoded_sentence=list()\n        for word in sentence.split():\n            if word not in vocab_to_int.keys():\n                encoded_sentence.append(0)\n            else:\n                encoded_sentence.append(vocab_to_int[word])\n        encoded_sentences.append(encoded_sentence)\n    return encoded_sentences","execution_count":415,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_sequences(encoded_sentences, sequence_length=250):\n   \n    features=np.zeros((len(encoded_sentences), sequence_length), dtype=int)\n    \n    for i, sentence in enumerate(encoded_sentences):\n        sentence_len=len(sentence)\n        if (sentence_len<=sequence_length):\n            zeros=list(np.zeros(sequence_length-sentence_len))\n            new=zeros+sentence\n        else:\n            new=sentence[:sequence_length]\n        features[i,:]=np.array(new)\n    return features","execution_count":416,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(sentences):\n    \n    formated_sentences, all_words = sentence_formatting(sentences)\n    encoded_sentences=encode_sentences(formated_sentences)\n    features=pad_sequences(encoded_sentences, 250)\n    return features","execution_count":417,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nencoded_sentences=encode_sentences(text_list)\nsentence_len=[len(encoded_sentence) for encoded_sentence in encoded_sentences]\npd.Series(sentence_len).hist()\nplt.show()\npd.Series(sentence_len).describe()","execution_count":418,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"execute_result","execution_count":418,"data":{"text/plain":"count    2523.000000\nmean       44.084423\nstd        50.691151\nmin         1.000000\n25%        14.000000\n50%        29.000000\n75%        54.000000\nmax       382.000000\ndtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=preprocess(text_list)\ntrain_x=features[:int(0.90*len(features))]\ntrain_y=sentiment_list[:int(0.90*len(features))]\nvalid_x=features[int(0.90*len(features)):]\nvalid_y=sentiment_list[int(0.90*len(features)):]\nprint(len(train_y), len(valid_y))","execution_count":419,"outputs":[{"output_type":"stream","text":"2270 253\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\n\ntrain_data=TensorDataset(torch.from_numpy(train_x), torch.from_numpy(np.asarray(train_y)))\nvalid_data=TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(np.asarray(valid_y)))\n\nbatch_size=50\ntrain_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True)","execution_count":420,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\nprint('Sample input size: ', sample_x.size())\nprint('Sample input: \\n', sample_x)\nprint()\nprint('Sample label size: ', sample_y.size())\nprint('Sample label: \\n', sample_y)","execution_count":421,"outputs":[{"output_type":"stream","text":"Sample input size:  torch.Size([50, 250])\nSample input: \n tensor([[    0,     0,     0,  ...,  1404,   699,  3833],\n        [    0,     0,     0,  ...,   105,  2124,    65],\n        [    0,     0,     0,  ...,     2,   574,    48],\n        ...,\n        [    0,     0,     0,  ..., 10410,   184,   333],\n        [    0,     0,     0,  ...,  2200,    13,   105],\n        [    0,     0,     0,  ...,     0,     0,    11]])\n\nSample label size:  torch.Size([50])\nSample label: \n tensor([1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n        1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2,\n        2, 1])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n \nclass SentimentalLSTM(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n        super().__init__()\n        self.output_size=output_size\n        self.n_layers=n_layers\n        self.hidden_dim=hidden_dim\n        \n        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n        \n        self.dropout=nn.Dropout(0.3)\n        \n        self.fc1=nn.Linear(hidden_dim, 64)\n        self.fc2=nn.Linear(64, 16)\n        self.fc3=nn.Linear(16,output_size)\n        self.sigmoid=nn.Sigmoid()\n        \n    def forward(self, x, hidden):\n        batch_size=x.size()\n        \n        embedd=self.embedding(x)\n        lstm_out, hidden=self.lstm(embedd, hidden)\n        \n        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n        \n        out=self.dropout(lstm_out)\n        out=self.fc1(out)\n        out=self.dropout(out)\n        out=self.fc2(out)\n        out=self.dropout(out)\n        out=self.fc3(out)\n        sig_out=self.sigmoid(out)\n        \n        sig_out=sig_out.view(batch_size, -1)\n        sig_out=sig_out[:, -1]\n        \n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n        \n        if (train_on_gpu):\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden","execution_count":422,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(vocab_to_int) + 1 \noutput_size = 1\nembedding_dim = 400\nhidden_dim = 256\nn_layers = 2\n\nnet = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\nprint(net)","execution_count":423,"outputs":[{"output_type":"stream","text":"SentimentalLSTM(\n  (embedding): Embedding(13539, 400)\n  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc1): Linear(in_features=256, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss and optimization functions\nlr=0.001\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\n# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\n# training params\n\nepochs = 3 # 3-4 is approx where I noticed the validation loss stop decreasing\n\ncounter = 0\nprint_every = 100\nclip=5 # gradient clipping\n\n# move model to GPU, if available\nif(train_on_gpu):\n    net.cuda()\n\nnet.train()\n# train for some number of epochs\nfor e in range(epochs):\n    # initialize hidden state\n    h = net.init_hidden(batch_size)\n\n    # batch loop\n    for inputs, labels in train_loader:\n        counter += 1\n\n        if(train_on_gpu):\n            inputs=inputs.cuda()\n            labels=labels.cuda()\n        # Creating new variables for the hidden state, otherwise\n        # we'd backprop through the entire training history\n        h = tuple([each.data for each in h])\n\n        # zero accumulated gradients\n        net.zero_grad()\n\n        # get the output from the model\n        output, h = net(inputs, h)\n\n        # calculate the loss and perform backprop\n        loss = criterion(output.squeeze(), labels.float())\n        loss.backward()\n        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n        nn.utils.clip_grad_norm_(net.parameters(), clip)\n        optimizer.step()\n        \n        # loss stats\n        if counter % print_every == 0:\n            # Get validation loss\n            val_h = net.init_hidden(batch_size)\n            val_losses = []\n            net.eval()\n            for inputs, labels in valid_loader:\n\n                # Creating new variables for the hidden state, otherwise\n                # we'd backprop through the entire training history\n                val_h = tuple([each.data for each in val_h])\n\n                inputs, labels = inputs.cuda(), labels.cuda()  \n                output, val_h = net(inputs, val_h)\n                val_loss = criterion(output.squeeze(), labels.float())\n\n                val_losses.append(val_loss.item())\n\n            net.train()\n            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n                  \"Step: {}...\".format(counter),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))","execution_count":424,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"too many indices for tensor of dimension 2","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-424-afa821d363f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# get the output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-422-213a73199b8b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msig_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msig_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0msig_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msig_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msig_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(test_data):\n    output_list=list()\n    batch_size=50   \n    net.eval()\n    with torch.no_grad():\n        test_review=preprocess(test_data)\n        for review in test_review:\n            # convert to tensor to pass into your model\n            feature_tensor = torch.from_numpy(review).view(1,-1)\n            if(train_on_gpu):\n                feature_tensor= feature_tensor.cuda()\n            batch_size = feature_tensor.size(0)\n            # initialize hidden state\n            h = net.init_hidden(batch_size)\n            # get the output from the model\n            output, h = net(feature_tensor, h)\n            pred = torch.round(output.squeeze()) \n            output_list.append(pred)\n        labels=[int(i.data.cpu().numpy()) for i in output_list]\n        return labels\nlabels=test_model(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame()\noutput['sentiment'] = labels\noutput","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}